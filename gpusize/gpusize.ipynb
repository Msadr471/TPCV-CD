{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad330148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import psutil\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "import torch\n",
    "from models.change_classifier import ChangeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e24f7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CORRECT MEMORY CALCULATION ===\n",
      "EfficientNet-B4 parameters: 19,000,000\n",
      "Your custom layers: 285,803\n",
      "TOTAL parameters: 19,285,803\n",
      "\n",
      "--- CORRECT Memory Breakdown for Batch Size 24 ---\n",
      "Model parameters: 73.57 MB\n",
      "Input data: 42.00 MB\n",
      "Activations (EfficientNet): 360.00 MB\n",
      "Gradients: 73.57 MB\n",
      "Optimizer states: 147.14 MB\n",
      "TOTAL ESTIMATED: 696.28 MB\n",
      "TOTAL ESTIMATED GB: 0.68 GB\n"
     ]
    }
   ],
   "source": [
    "def calculate_memory_correct(batch_size=24, image_size=256):\n",
    "    \"\"\"\n",
    "    CORRECT memory calculation including EfficientNet backbone\n",
    "    \"\"\"\n",
    "    print(\"=== CORRECT MEMORY CALCULATION ===\")\n",
    "    \n",
    "    # 1. Get TOTAL parameters (EfficientNet-B4 + your layers)\n",
    "    # EfficientNet-B4: ~19M parameters\n",
    "    # Your custom layers: ~285K parameters\n",
    "    efficientnet_params = 19_000_000\n",
    "    custom_params = 285_803\n",
    "    total_params = efficientnet_params + custom_params\n",
    "    \n",
    "    print(f\"EfficientNet-B4 parameters: {efficientnet_params:,}\")\n",
    "    print(f\"Your custom layers: {custom_params:,}\")\n",
    "    print(f\"TOTAL parameters: {total_params:,}\")\n",
    "    \n",
    "    # 2. Calculate memory components\n",
    "    bytes_per_float = 4  # float32\n",
    "    \n",
    "    # Model parameters memory\n",
    "    params_memory_mb = (total_params * bytes_per_float) / (1024 * 1024)\n",
    "    \n",
    "    # Input data memory\n",
    "    single_image_memory = (image_size * image_size * 3 * bytes_per_float) / (1024 * 1024)\n",
    "    single_mask_memory = (image_size * image_size * 1 * bytes_per_float) / (1024 * 1024)\n",
    "    single_sample_memory = (2 * single_image_memory) + single_mask_memory\n",
    "    input_data_memory_mb = batch_size * single_sample_memory\n",
    "    \n",
    "    # Gradients memory\n",
    "    gradients_memory_mb = params_memory_mb\n",
    "    \n",
    "    # Optimizer states (FAdam uses 2x parameters)\n",
    "    optimizer_memory_mb = 2 * params_memory_mb\n",
    "    \n",
    "    # 3. EFFICIENTNET ACTIVATIONS MEMORY (THIS IS THE KILLER!)\n",
    "    # EfficientNet-B4 feature maps at different resolutions:\n",
    "    # These are approximate sizes for batch size 1:\n",
    "    level1_memory = (128 * 128 * 48 * bytes_per_float) / (1024 * 1024)   # 3.0 MB\n",
    "    level2_memory = (64 * 64 * 64 * bytes_per_float) / (1024 * 1024)     # 1.0 MB  \n",
    "    level3_memory = (32 * 32 * 112 * bytes_per_float) / (1024 * 1024)    # 0.44 MB\n",
    "    level4_memory = (16 * 16 * 192 * bytes_per_float) / (1024 * 1024)    # 0.19 MB\n",
    "    level5_memory = (8 * 8 * 320 * bytes_per_float) / (1024 * 1024)      # 0.08 MB\n",
    "    \n",
    "    # Total activations per sample ≈ 5 MB\n",
    "    # For batch size 24: 24 × 5 MB = 120 MB\n",
    "    # But wait! During backward pass, we need to store ALL intermediate activations!\n",
    "    # PyTorch keeps them for gradient calculation\n",
    "    \n",
    "    # REAL activations memory: 3-4x more due to:\n",
    "    # - Intermediate computations\n",
    "    # - Feature maps at all levels\n",
    "    # - Gradient computation requirements\n",
    "    activations_per_sample = 15 * 1024 * 1024  # ~15 MB per sample (conservative)\n",
    "    activations_memory_mb = batch_size * activations_per_sample / (1024 * 1024)\n",
    "    \n",
    "    # 4. Total memory usage\n",
    "    total_memory_mb = (\n",
    "        params_memory_mb +\n",
    "        input_data_memory_mb +\n",
    "        activations_memory_mb +\n",
    "        gradients_memory_mb +\n",
    "        optimizer_memory_mb\n",
    "    )\n",
    "    \n",
    "    # 5. Print results\n",
    "    print(f\"\\n--- CORRECT Memory Breakdown for Batch Size {batch_size} ---\")\n",
    "    print(f\"Model parameters: {params_memory_mb:.2f} MB\")\n",
    "    print(f\"Input data: {input_data_memory_mb:.2f} MB\")\n",
    "    print(f\"Activations (EfficientNet): {activations_memory_mb:.2f} MB\")\n",
    "    print(f\"Gradients: {gradients_memory_mb:.2f} MB\")\n",
    "    print(f\"Optimizer states: {optimizer_memory_mb:.2f} MB\")\n",
    "    print(f\"TOTAL ESTIMATED: {total_memory_mb:.2f} MB\")\n",
    "    print(f\"TOTAL ESTIMATED GB: {total_memory_mb/1024:.2f} GB\")\n",
    "    \n",
    "    return total_memory_mb\n",
    "\n",
    "# Run the correct calculation\n",
    "if __name__ == \"__main__\":\n",
    "    calculate_memory_correct(batch_size=24, image_size=256)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
